{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93407648",
   "metadata": {},
   "source": [
    "# LangChain & LangGraph Practice: Building Agentic AI Workflows\n",
    "\n",
    "Welcome to this hands-on practice notebook for building Agentic AI workflows using LangChain and LangGraph!\n",
    "\n",
    "## What You'll Learn:\n",
    "- üîß Set up LangChain and LangGraph environments\n",
    "- ü§ñ Create simple and complex AI agents\n",
    "- üîó Build graph-based workflows with multiple agents\n",
    "- üõ†Ô∏è Integrate external tools and APIs\n",
    "- üíæ Implement memory and state management\n",
    "- üîÄ Create conditional workflow paths\n",
    "- üß™ Test and debug agent workflows\n",
    "\n",
    "## Prerequisites:\n",
    "- Basic Python knowledge\n",
    "- OpenAI API key (or other LLM provider)\n",
    "- Understanding of AI/ML concepts (helpful but not required)\n",
    "\n",
    "Let's start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e8770",
   "metadata": {},
   "source": [
    "## 1. Setup and Install Dependencies\n",
    "\n",
    "First, let's install all the required packages for our LangChain and LangGraph practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Run this cell if packages are not already installed\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langchain-community\", \n",
    "    \"langchain-openai\",\n",
    "    \"langgraph\",\n",
    "    \"python-dotenv\",\n",
    "    \"matplotlib\",\n",
    "    \"pandas\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062f253",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Import all the necessary libraries for building our agentic workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d79a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import json\n",
    "from typing import TypedDict, Annotated, Literal, List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "# Utility imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")\n",
    "print(\"üöÄ Ready to build agentic workflows!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0fb10",
   "metadata": {},
   "source": [
    "## 3. Configure API Keys and Environment\n",
    "\n",
    "‚ö†Ô∏è **Important**: You'll need to set up your API keys to run the examples.\n",
    "\n",
    "### Option 1: Create a `.env` file\n",
    "Create a `.env` file in your project directory with:\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_API_KEY=your_langsmith_api_key_here\n",
    "```\n",
    "\n",
    "### Option 2: Set directly in the notebook (less secure)\n",
    "Uncomment and modify the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17407f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Option 2: Set API keys directly (uncomment and modify)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"your_langsmith_api_key_here\"\n",
    "\n",
    "# Check if API key is set\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"‚úÖ OpenAI API key is configured\")\n",
    "    print(f\"üîë Key starts with: {api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API key not found\")\n",
    "    print(\"üìù Please set OPENAI_API_KEY in your .env file or directly in the cell above\")\n",
    "\n",
    "# Optional: Check LangSmith setup\n",
    "if os.getenv(\"LANGCHAIN_API_KEY\"):\n",
    "    print(\"‚úÖ LangSmith tracing is configured\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è LangSmith tracing not configured (optional for learning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5cd6a",
   "metadata": {},
   "source": [
    "## 4. Create a Simple LangChain Agent\n",
    "\n",
    "Let's start with a basic LangChain agent that can use tools to perform tasks.\n",
    "\n",
    "### Exercise 4.1: Simple Calculator Agent\n",
    "We'll create an agent that can perform mathematical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple calculator tool\n",
    "def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs mathematical calculations.\n",
    "    Args:\n",
    "        expression: A mathematical expression as a string (e.g., \"2 + 3 * 4\")\n",
    "    Returns:\n",
    "        The result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Be careful with eval in production! This is for learning purposes.\n",
    "        result = eval(expression)\n",
    "        return f\"The result of {expression} is: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating {expression}: {str(e)}\"\n",
    "\n",
    "# Create the tool\n",
    "calculator = Tool(\n",
    "    name=\"calculator\",\n",
    "    description=\"Useful for performing mathematical calculations. Input should be a mathematical expression.\",\n",
    "    func=calculator_tool\n",
    ")\n",
    "\n",
    "# Test the tool\n",
    "print(\"üßÆ Testing calculator tool:\")\n",
    "print(calculator.run(\"15 + 25\"))\n",
    "print(calculator.run(\"(10 * 5) / 2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba552e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "# Create tools list\n",
    "tools = [calculator]\n",
    "\n",
    "# Get the prompt from LangChain hub\n",
    "try:\n",
    "    prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "    print(\"‚úÖ Prompt loaded from LangChain hub\")\n",
    "except:\n",
    "    # Fallback prompt if hub is not available\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant that can use tools to help answer questions.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    print(\"‚úÖ Using fallback prompt\")\n",
    "\n",
    "# Create the agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Calculator agent created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with different mathematical queries\n",
    "test_queries = [\n",
    "    \"What is 15 multiplied by 23?\",\n",
    "    \"Calculate the area of a circle with radius 5 (use œÄ = 3.14159)\",\n",
    "    \"If I invest $1000 at 5% annual interest for 3 years, how much will I have? Use compound interest formula.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing the calculator agent:\\n\")\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"üìù Test {i}: {query}\")\n",
    "    try:\n",
    "        result = agent_executor.invoke({\"input\": query})\n",
    "        print(f\"‚úÖ Result: {result['output']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8042258",
   "metadata": {},
   "source": [
    "## 5. Build Basic LangGraph Workflow\n",
    "\n",
    "Now let's create a simple graph-based workflow using LangGraph. This workflow will analyze a problem and provide recommendations.\n",
    "\n",
    "### Exercise 5.1: Problem Analysis Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state for our workflow\n",
    "class AnalysisState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    problem: str\n",
    "    analysis: str\n",
    "    recommendations: str\n",
    "    current_step: str\n",
    "\n",
    "# Define workflow nodes\n",
    "def analyze_problem(state: AnalysisState) -> AnalysisState:\n",
    "    \"\"\"Analyze the user's problem\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert analyst. Analyze the given problem thoroughly, identifying key issues, root causes, and important factors.\"),\n",
    "        (\"human\", \"Problem: {problem}\\n\\nProvide a detailed analysis:\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    analysis = chain.invoke({\"problem\": state[\"problem\"]})\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"analysis\": analysis,\n",
    "        \"current_step\": \"analysis_complete\"\n",
    "    }\n",
    "\n",
    "def generate_recommendations(state: AnalysisState) -> AnalysisState:\n",
    "    \"\"\"Generate recommendations based on the analysis\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Based on the analysis provided, generate 3-5 practical, actionable recommendations with clear steps.\"),\n",
    "        (\"human\", \"Problem: {problem}\\n\\nAnalysis: {analysis}\\n\\nProvide specific recommendations:\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    recommendations = chain.invoke({\n",
    "        \"problem\": state[\"problem\"],\n",
    "        \"analysis\": state[\"analysis\"]\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"recommendations\": recommendations,\n",
    "        \"current_step\": \"recommendations_complete\"\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Workflow nodes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1dd3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow graph\n",
    "workflow = StateGraph(AnalysisState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"analyze\", analyze_problem)\n",
    "workflow.add_node(\"recommend\", generate_recommendations)\n",
    "\n",
    "# Define the flow\n",
    "workflow.set_entry_point(\"analyze\")\n",
    "workflow.add_edge(\"analyze\", \"recommend\")\n",
    "workflow.add_edge(\"recommend\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"üîÑ LangGraph workflow created!\")\n",
    "\n",
    "# Test the workflow\n",
    "test_problems = [\n",
    "    \"I want to learn machine learning but don't know where to start and feel overwhelmed by all the options.\",\n",
    "    \"My team is struggling with communication in remote work setup.\",\n",
    "    \"I need to decide between Python and JavaScript for my next web development project.\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Testing the analysis workflow:\\n\")\n",
    "\n",
    "for i, problem in enumerate(test_problems, 1):\n",
    "    print(f\"üìù Problem {i}: {problem}\")\n",
    "    \n",
    "    result = app.invoke({\n",
    "        \"messages\": [],\n",
    "        \"problem\": problem,\n",
    "        \"analysis\": \"\",\n",
    "        \"recommendations\": \"\",\n",
    "        \"current_step\": \"start\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüìä Analysis:\\n{result['analysis']}\")\n",
    "    print(f\"\\nüí° Recommendations:\\n{result['recommendations']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca93fa",
   "metadata": {},
   "source": [
    "## 6. Create Multi-Agent Workflow\n",
    "\n",
    "Let's build a more complex workflow with multiple specialized agents that collaborate on tasks.\n",
    "\n",
    "### Exercise 6.1: Content Creation Workflow\n",
    "We'll create a workflow with different agents for different types of content creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for multi-agent workflow\n",
    "class MultiAgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task_type: str\n",
    "    user_input: str\n",
    "    content: str\n",
    "    review_feedback: str\n",
    "    final_output: str\n",
    "    iteration_count: int\n",
    "\n",
    "# Classifier agent\n",
    "def classify_task(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Classify the type of content creation task\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Classify the user's request into one of these categories:\n",
    "        - 'technical': Code, documentation, technical explanations\n",
    "        - 'creative': Stories, poems, creative writing\n",
    "        - 'business': Reports, proposals, business content\n",
    "        - 'educational': Tutorials, explanations, learning materials\n",
    "        \n",
    "        Respond with just the category name.\"\"\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    task_type = chain.invoke({\"input\": state[\"user_input\"]}).strip().lower()\n",
    "    \n",
    "    return {**state, \"task_type\": task_type, \"iteration_count\": 0}\n",
    "\n",
    "# Specialized agents\n",
    "def technical_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Create technical content\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a technical expert. Create accurate, detailed technical content with examples and clear explanations.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    content = chain.invoke({\"input\": state[\"user_input\"]})\n",
    "    \n",
    "    return {**state, \"content\": content}\n",
    "\n",
    "def creative_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Create creative content\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.8)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a creative writer. Create engaging, imaginative content with vivid descriptions and compelling narratives.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    content = chain.invoke({\"input\": state[\"user_input\"]})\n",
    "    \n",
    "    return {**state, \"content\": content}\n",
    "\n",
    "def business_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Create business content\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a business professional. Create clear, professional business content with structured formatting and actionable insights.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    content = chain.invoke({\"input\": state[\"user_input\"]})\n",
    "    \n",
    "    return {**state, \"content\": content}\n",
    "\n",
    "def educational_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Create educational content\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.4)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an educator. Create clear, step-by-step educational content with examples and practical exercises.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    content = chain.invoke({\"input\": state[\"user_input\"]})\n",
    "    \n",
    "    return {**state, \"content\": content}\n",
    "\n",
    "print(\"‚úÖ Multi-agent system defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09371f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing logic\n",
    "def route_to_agent(state: MultiAgentState) -> Literal[\"technical\", \"creative\", \"business\", \"educational\"]:\n",
    "    \"\"\"Route to the appropriate agent based on task type\"\"\"\n",
    "    task_type = state[\"task_type\"]\n",
    "    return task_type if task_type in [\"technical\", \"creative\", \"business\", \"educational\"] else \"educational\"\n",
    "\n",
    "# Review agent\n",
    "def review_content(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Review the generated content\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Review the content and provide feedback. Rate it 1-10 and suggest improvements.\n",
    "        If the score is 8 or above, respond with 'APPROVED: [score]/10 - [brief positive feedback]'\n",
    "        If below 8, provide specific improvement suggestions.\"\"\"),\n",
    "        (\"human\", \"Content to review: {content}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    feedback = chain.invoke({\"content\": state[\"content\"]})\n",
    "    \n",
    "    return {\n",
    "        **state, \n",
    "        \"review_feedback\": feedback,\n",
    "        \"iteration_count\": state[\"iteration_count\"] + 1\n",
    "    }\n",
    "\n",
    "def should_finalize(state: MultiAgentState) -> Literal[\"finalize\", \"revise\"]:\n",
    "    \"\"\"Decide whether to finalize or revise\"\"\"\n",
    "    feedback = state[\"review_feedback\"].lower()\n",
    "    max_iterations = 2\n",
    "    \n",
    "    if \"approved\" in feedback or state[\"iteration_count\"] >= max_iterations:\n",
    "        return \"finalize\"\n",
    "    else:\n",
    "        return \"revise\"\n",
    "\n",
    "def finalize_output(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Finalize the output\"\"\"\n",
    "    return {**state, \"final_output\": state[\"content\"]}\n",
    "\n",
    "def revise_content(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Revise content based on feedback\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Revise the content based on the feedback provided. Improve quality and address concerns.\"),\n",
    "        (\"human\", \"Original request: {user_input}\\n\\nCurrent content: {content}\\n\\nFeedback: {feedback}\\n\\nProvide improved version:\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    revised_content = chain.invoke({\n",
    "        \"user_input\": state[\"user_input\"],\n",
    "        \"content\": state[\"content\"],\n",
    "        \"feedback\": state[\"review_feedback\"]\n",
    "    })\n",
    "    \n",
    "    return {**state, \"content\": revised_content}\n",
    "\n",
    "print(\"‚úÖ Routing and review logic defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multi-agent workflow\n",
    "multi_workflow = StateGraph(MultiAgentState)\n",
    "\n",
    "# Add all nodes\n",
    "multi_workflow.add_node(\"classify\", classify_task)\n",
    "multi_workflow.add_node(\"technical\", technical_agent)\n",
    "multi_workflow.add_node(\"creative\", creative_agent)\n",
    "multi_workflow.add_node(\"business\", business_agent)\n",
    "multi_workflow.add_node(\"educational\", educational_agent)\n",
    "multi_workflow.add_node(\"review\", review_content)\n",
    "multi_workflow.add_node(\"revise\", revise_content)\n",
    "multi_workflow.add_node(\"finalize\", finalize_output)\n",
    "\n",
    "# Define the flow\n",
    "multi_workflow.set_entry_point(\"classify\")\n",
    "\n",
    "# Route to appropriate agent\n",
    "multi_workflow.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"technical\": \"technical\",\n",
    "        \"creative\": \"creative\", \n",
    "        \"business\": \"business\",\n",
    "        \"educational\": \"educational\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# All agents go to review\n",
    "multi_workflow.add_edge(\"technical\", \"review\")\n",
    "multi_workflow.add_edge(\"creative\", \"review\")\n",
    "multi_workflow.add_edge(\"business\", \"review\")\n",
    "multi_workflow.add_edge(\"educational\", \"review\")\n",
    "\n",
    "# Conditional routing after review\n",
    "multi_workflow.add_conditional_edges(\n",
    "    \"review\",\n",
    "    should_finalize,\n",
    "    {\n",
    "        \"finalize\": \"finalize\",\n",
    "        \"revise\": \"revise\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# After revision, go back to review\n",
    "multi_workflow.add_edge(\"revise\", \"review\")\n",
    "multi_workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "# Compile the multi-agent workflow\n",
    "multi_app = multi_workflow.compile()\n",
    "\n",
    "print(\"ü§ñ Multi-agent workflow created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72028fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the multi-agent workflow\n",
    "test_requests = [\n",
    "    \"Write a Python function to implement bubble sort with comments\",\n",
    "    \"Create a short story about a time traveler who gets stuck in 1920s Paris\",\n",
    "    \"Draft a business proposal for a new employee wellness program\",\n",
    "    \"Explain how photosynthesis works with simple examples for high school students\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing multi-agent workflow:\\n\")\n",
    "\n",
    "for i, request in enumerate(test_requests, 1):\n",
    "    print(f\"üìù Request {i}: {request}\")\n",
    "    \n",
    "    result = multi_app.invoke({\n",
    "        \"messages\": [],\n",
    "        \"task_type\": \"\",\n",
    "        \"user_input\": request,\n",
    "        \"content\": \"\",\n",
    "        \"review_feedback\": \"\",\n",
    "        \"final_output\": \"\",\n",
    "        \"iteration_count\": 0\n",
    "    })\n",
    "    \n",
    "    print(f\"üè∑Ô∏è Task Type: {result['task_type']}\")\n",
    "    print(f\"üîÑ Iterations: {result['iteration_count']}\")\n",
    "    print(f\"üìä Final Review: {result['review_feedback'][:100]}...\")\n",
    "    print(f\"‚úÖ Final Output:\\n{result['final_output'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21e8b3",
   "metadata": {},
   "source": [
    "## 7. Implement Tool Integration\n",
    "\n",
    "Let's add external tools and APIs to our agents for enhanced capabilities.\n",
    "\n",
    "## 8. Add Memory and State Management\n",
    "\n",
    "Implement conversation memory and state persistence.\n",
    "\n",
    "## 9. Create Conditional Workflow Paths\n",
    "\n",
    "Build dynamic workflows with conditional branching.\n",
    "\n",
    "## 10. Test and Debug Agent Workflows\n",
    "\n",
    "Create comprehensive test cases and debugging strategies.\n",
    "\n",
    "### üéØ Practice Exercises\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "1. **Custom Tool Creation**: Create a tool that fetches weather data or current time\n",
    "2. **Memory Enhancement**: Add long-term memory to store user preferences\n",
    "3. **Complex Routing**: Create a workflow that routes based on multiple conditions\n",
    "4. **Error Handling**: Add robust error handling and recovery mechanisms\n",
    "5. **Performance Optimization**: Implement caching and optimize LLM calls\n",
    "\n",
    "### üìö Next Steps\n",
    "\n",
    "- Explore LangSmith for monitoring and debugging\n",
    "- Try different LLM providers (Anthropic, Google, etc.)\n",
    "- Build domain-specific agents for your use case\n",
    "- Integrate with external APIs and databases\n",
    "- Deploy your agents to production\n",
    "\n",
    "### üîó Useful Resources\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangSmith for Monitoring](https://smith.langchain.com/)\n",
    "- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)\n",
    "\n",
    "Happy building! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
